# ðŸŽ¯ E-Commerce AI Analyst

**A GenAI-powered agentic system for querying e-commerce operations data using natural language.**

Transform business questions into actionable insights in seconds. No SQL knowledge required.

---

## ðŸŒŸ Features

âœ¨ **Natural Language Queries** - Ask questions in plain English, get instant answers  
ðŸ¤– **AI-Powered SQL Generation** - Google Gemini converts natural language to SQL  
ðŸ’¡ **Automated Insights** - AI analyzes results and provides business intelligence  
ðŸ“Š **Real-time Results** - Visualize data with interactive tables and charts  
ðŸ’¾ **Export & History** - Download results as CSV, track all queries  
ðŸ”„ **Multi-turn Conversations** - Context-aware dialogue with conversation memory  
ðŸ“± **Clean Interface** - Intuitive Streamlit UI for any operations team member  

---
Working Demonstration video-https://youtu.be/UsQ2i6ODjxU
github link- https://github.com/asvithreddy/maersk-ecommerce-ai
## ðŸ“‹ Table of Contents

- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Usage](#-usage)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Dataset](#-dataset)
- [Sample Queries](#-sample-queries)
- [Design Decisions](#-design-decisions)
- [Future Enhancements](#-future-enhancements)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## ðŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Google API Key (free: https://aistudio.google.com/apikey)
- Kaggle dataset (download from: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/)

### One-Minute Setup

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/maersk-ecommerce-ai.git
cd maersk-ecommerce-ai

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure API key
echo "GOOGLE_API_KEY=your_api_key_here" > .env

# Download dataset to data/ folder
# (From https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/)
# Extract ZIP to ./data/ folder

# Run application
streamlit run app.py
```

Open browser to `http://localhost:8501` âœ…

---

## ðŸ“¦ Installation

### Step 1: Clone Repository

```bash
git clone https://github.com/YOUR_USERNAME/maersk-ecommerce-ai.git
cd maersk-ecommerce-ai
```

### Step 2: Virtual Environment

```bash
# Create
python -m venv venv

# Activate
# On Windows (PowerShell):
venv\Scripts\Activate.ps1
# On Windows (CMD):
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

Expected packages:
```
âœ“ streamlit==1.28.1
âœ“ pandas==2.0.3
âœ“ google-generativeai==0.3.0
âœ“ python-dotenv (auto-installed)
```

### Step 4: Get API Keys

**Google Gemini API Key:**
1. Go to https://aistudio.google.com/apikey
2. Click "Create API Key"
3. Copy the key

**Create `.env` file:**
```bash
cat > .env << EOF
GOOGLE_API_KEY=your_key_here
EOF
```

**âš ï¸ IMPORTANT:** Never commit `.env` file. It's in `.gitignore`.

### Step 5: Download Dataset

**Option A: Manual (Easiest)**
1. Go to https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/
2. Click "Download" button
3. Extract ZIP to `data/` folder in your project
4. Verify these 8 files are in `data/`:
   - `olist_orders_dataset.csv`
   - `olist_order_items_dataset.csv`
   - `olist_products_dataset.csv`
   - `olist_customers_dataset.csv`
   - `olist_sellers_dataset.csv`
   - `olist_order_payments_dataset.csv`
   - `olist_order_reviews_dataset.csv`
   - `product_category_name_translation.csv`

**Option B: Kaggle CLI**
```bash
pip install kaggle
# Configure: https://www.kaggle.com/account
kaggle datasets download -d olistbr/brazilian-ecommerce
unzip brazilian-ecommerce.zip -d data/
```

### Step 6: Run Application

```bash
streamlit run app.py
```

App will open at `http://localhost:8501`

---

## ðŸ’¬ Usage

### Basic Query

1. **Type or select a question** - Use sidebar templates or type custom question
2. **Click "Analyze"** - System processes your query
3. **View results** - SQL, data table, and AI insights appear
4. **Export or explore** - Download CSV or view history

### Example Questions

```
"Which product category has the highest revenue?"
"What is the average order value?"
"Show me top 10 sellers by order count"
"What payment methods are most common?"
"Which cities have the most customers?"
"Show me customer distribution by state"
"What is the average review rating?"
```

### Features

**Export Results:**
- Click "ðŸ“¥ Download CSV" button
- Results saved as `results_YYYYMMDD_HHMMSS.csv`

**Query History:**
- Expand "ðŸ“‹ Query History" section
- Shows last 10 queries with timestamps
- Click to see exact SQL generated

**Multiple Queries:**
- Ask follow-up questions
- System maintains context
- Session memory preserved during app session

---

## ðŸ—ï¸ Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE                    â”‚
â”‚         Streamlit Web Application (Python)          â”‚
â”‚  Chat Input â”‚ Sample Questions â”‚ Results Display    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CONVERSATION LAYER                     â”‚
â”‚  â€¢ Session State Management                         â”‚
â”‚  â€¢ Query History (timestamps, SQL)                  â”‚
â”‚  â€¢ Context Preservation                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ SQL GEN â”‚    â”‚ ANALYSIS â”‚
    â”‚ AGENT   â”‚    â”‚ AGENT    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚               â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  GEMINI 2.0 FLASH LLM   â”‚
    â”‚  â€¢ SQL Generation       â”‚
    â”‚  â€¢ Result Analysis      â”‚
    â”‚  â€¢ Insight Generation   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DATA & QUERY EXECUTION   â”‚
    â”‚  â€¢ SQLite Database        â”‚
    â”‚  â€¢ Query Validation       â”‚
    â”‚  â€¢ Thread-Safe Execution  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   BRAZILIAN ECOMMERCE     â”‚
    â”‚   DATASET (100k+ records) â”‚
    â”‚  â€¢ Orders                 â”‚
    â”‚  â€¢ Products               â”‚
    â”‚  â€¢ Customers              â”‚
    â”‚  â€¢ Sellers                â”‚
    â”‚  â€¢ Payments               â”‚
    â”‚  â€¢ Reviews                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Query Pipeline

```
1. USER QUESTION
   â†“
2. SCHEMA RETRIEVAL
   â””â”€ Get table & column names
   â†“
3. PROMPT CONSTRUCTION
   â””â”€ Add schema, rules, examples
   â†“
4. LLM CALL (Gemini)
   â””â”€ Generate SQL
   â†“
5. SQL CLEANING & VALIDATION
   â””â”€ Remove artifacts, verify SELECT
   â†“
6. DATABASE EXECUTION
   â””â”€ Run on SQLite
   â†“
7. RESULT PROCESSING
   â””â”€ Format for display
   â†“
8. INSIGHT GENERATION
   â””â”€ LLM analyzes results
   â†“
9. UI RENDERING
   â””â”€ Display in Streamlit
```

### Database Schema

**8 Tables (100k+ records):**

| Table | Rows | Purpose |
|-------|------|---------|
| `orders` | 99,441 | Order metadata, status, timestamps |
| `order_items` | 879,505 | Items per order, pricing, seller info |
| `products` | 32,951 | Product catalog, categories, attributes |
| `customers` | 96,096 | Customer data, location, contact |
| `sellers` | 16,008 | Seller information and location |
| `order_payments` | 103,886 | Payment methods, amounts, installments |
| `order_reviews` | 99,224 | Customer reviews, ratings, comments |
| `product_category_translation` | 71 | Portuguese â†’ English category names |

**Entity Relationships:**
```
orders â†’ order_items â† products
  â†“                      â†“
customers            product_category
  â†“
order_payments

orders â†’ order_reviews
```

---

## ðŸ› ï¸ Tech Stack

### Core Dependencies

```
streamlit==1.28.1              # Web UI framework
pandas==2.0.3                  # Data manipulation
google-generativeai==0.3.0     # Gemini API access
python-dotenv==1.0.0           # Environment variables
sqlite3 (built-in)             # Database
```

### Architecture Choices

**Why Streamlit?**
- âœ… Rapid development (write Python, get web app)
- âœ… Built for data applications
- âœ… Session state management for conversation
- âœ… Easy deployment (Streamlit Cloud)
- âœ… Zero frontend knowledge needed

**Why Gemini 2.0 Flash?**
- âœ… Free tier with high rate limits
- âœ… Excellent SQL generation capability
- âœ… Fast inference (flash variant)
- âœ… Natural language understanding
- âœ… Good reasoning for business logic

**Why SQLite?**
- âœ… File-based, no server needed
- âœ… Fast for 100k+ record queries
- âœ… Full SQL support
- âœ… Perfect for development & demos
- âœ… Can scale to PostgreSQL if needed

**Why Pandas?**
- âœ… Standard for data processing
- âœ… Easy SQL â†’ DataFrame conversion
- âœ… CSV export, data manipulation
- âœ… Well-integrated with Streamlit

---

## ðŸ“Š Dataset

### Brazilian E-Commerce (Olist)

**Source:** https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/

**Coverage:**
- ðŸ“… **Time Period:** 2016-2018
- ðŸŒ **Geographic:** Brazilian states, 4,119 cities
- ðŸ“¦ **Orders:** 99,441 complete orders
- ðŸ›ï¸ **Items:** 879,505 order line items
- ðŸ“ **Products:** 32,951 unique products
- ðŸ‘¥ **Customers:** 96,096 unique customers
- ðŸª **Sellers:** 16,008 registered sellers
- â­ **Reviews:** 99,224 customer reviews

**Key Statistics:**
- Average order value: ~$150
- Most common category: Electronics
- Top state: SÃ£o Paulo (SP)
- Most used payment: Credit card
- Average review rating: 4.2/5

**Data Quality:**
- âœ… No missing critical values
- âœ… Properly typed columns (dates, numerics)
- âœ… Valid geographic data
- âœ… Consistent foreign keys

---

## ðŸ’¡ Sample Queries

These queries demonstrate the system's capabilities:

### Analytics Query
```
Question: "Which product category has the highest revenue?"

Generated SQL:
SELECT p.product_category_name, SUM(oi.price) as total_revenue 
FROM products p 
JOIN order_items oi ON p.product_id = oi.product_id 
GROUP BY p.product_category_name 
ORDER BY total_revenue DESC 
LIMIT 10;

Output: Electronics, Fashion, Home, Sports with revenue figures
Insight: Electronics leads with $X, representing 35% of total revenue
```

### Aggregation Query
```
Question: "What payment methods are most common?"

Generated SQL:
SELECT payment_type, COUNT(*) as count, 
  ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 2) as percentage
FROM order_payments 
GROUP BY payment_type 
ORDER BY count DESC;

Output: Credit Card (76%), Boleto (18%), Debit (5%), Voucher (1%)
Insight: Credit card dominates, representing over 3/4 of all transactions
```

### Geographic Query
```
Question: "Which cities have the most customers?"

Generated SQL:
SELECT customer_city, customer_state, COUNT(*) as customer_count
FROM customers
GROUP BY customer_city, customer_state
ORDER BY customer_count DESC
LIMIT 15;

Output: SÃ£o Paulo (SP), Rio de Janeiro (RJ), Belo Horizonte (MG), etc.
Insight: Top 3 cities account for 45% of all customers
```

### Multi-Table Query
```
Question: "Show me top sellers by revenue"

Generated SQL:
SELECT oi.seller_id, s.seller_state, COUNT(*) as order_count,
  SUM(oi.price) as total_revenue
FROM order_items oi
JOIN sellers s ON oi.seller_id = s.seller_id
GROUP BY oi.seller_id, s.seller_state
ORDER BY total_revenue DESC
LIMIT 10;

Output: Seller rankings with revenue and order counts
Insight: Top 10 sellers account for 28% of total revenue
```

---

## ðŸŽ¨ Design Decisions

### 1. Multi-Agent Architecture (vs. Single LLM)

**Decision:** Separate SQL Generation and Analysis agents

**Why:**
- Allows specialized prompts for each task
- SQL generation needs strict formatting, analysis needs creativity
- Easier to debug and maintain
- Can swap agents independently

**Trade-off:** Slightly more API calls, but better reliability

```python
# Specialized agents
agent_sql = generate_sql_from_question(question, schema)
agent_analysis = generate_insight(question, results)
```

---

### 2. Template Fallback Queries

**Decision:** Maintain pre-written SQL templates for common questions

**Why:**
- Fallback if Gemini fails or returns malformed SQL
- Ensures reliability for common operations
- Faster response for predictable questions
- Cost savings (skip API call if template matches)

**Template Examples:**
```python
TEMPLATE_QUERIES = {
    "average order value": "SELECT AVG(payment_value) ...",
    "highest revenue category": "SELECT p.category, SUM(price) ...",
    "top sellers": "SELECT seller_id, SUM(price) ...",
}
```

---

### 3. Thread-Safe SQLite Access

**Decision:** `check_same_thread=False` + fresh connections per query

**Why:**
- Streamlit runs on multiple threads
- SQLite is thread-sensitive by default
- Creating fresh connections avoids state conflicts
- Each query gets isolated execution context

**Implementation:**
```python
# Instead of reusing connection
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
# Fresh connection per query
df = pd.read_sql_query(sql, conn)
conn.close()
```

---

### 4. Aggressive SQL Cleaning

**Decision:** Multiple cleaning passes to handle LLM output variations

**Why:**
- LLM sometimes adds prefixes ("ite SELECT"), markdown, explanations
- Need bulletproof SQL extraction
- Better error detection

**Implementation:**
```python
sql = response.text.strip()
sql = sql.replace("```sql", "").replace("```", "").strip()
sql = sql.replace("SQLite", "").strip()
# Validate it starts with SELECT
if not sql.upper().startswith("SELECT"):
    return None  # Use template fallback
```

---

### 5. Session State for Conversation Memory

**Decision:** Streamlit `st.session_state` for query history

**Why:**
- Built into Streamlit, no external DB needed
- Perfect for single-session demos
- Preserves context across interactions
- User can review what was asked/executed

**Trade-off:** History lost on page refresh (acceptable for MVP)

```python
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

st.session_state.chat_history.append({
    "question": user_question,
    "sql": sql_query,
    "timestamp": datetime.now()
})
```

---

### 6. Schema Limiting in Prompts

**Decision:** Show only 10 columns per table, 8 tables max in prompt

**Why:**
- Token limits on LLM input
- Too much schema = confusion for model
- Reduces hallucination of non-existent columns
- Keeps prompt concise

**Result:** Better SQL generation, lower latency

---

## ðŸ“ Project Structure

```
maersk-ecommerce-ai/
â”‚
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env.example                    # Example environment variables
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ data/                           # Dataset (not in repo)
â”‚   â”œâ”€â”€ olist_orders_dataset.csv
â”‚   â”œâ”€â”€ olist_order_items_dataset.csv
â”‚   â”œâ”€â”€ olist_products_dataset.csv
â”‚   â”œâ”€â”€ olist_customers_dataset.csv
â”‚   â”œâ”€â”€ olist_sellers_dataset.csv
â”‚   â”œâ”€â”€ olist_order_payments_dataset.csv
â”‚   â”œâ”€â”€ olist_order_reviews_dataset.csv
â”‚   â””â”€â”€ product_category_name_translation.csv
â”‚
â””â”€â”€ docs/                           # Documentation (optional)
    â”œâ”€â”€ ARCHITECTURE.md             # Detailed architecture
    â”œâ”€â”€ SETUP.md                    # Detailed setup guide
    â””â”€â”€ API_REFERENCE.md            # Function documentation
```

---

## ðŸ”® Future Enhancements

### Phase 1: Advanced Analytics (1-2 weeks)

**Forecasting & Trends:**
- Time-series forecasting (ARIMA, Prophet)
- Seasonal decomposition
- YoY trend analysis
- Anomaly detection

```python
# Example enhancement
def forecast_sales(category, months=3):
    data = get_sales_by_month(category)
    forecast = arima_forecast(data, periods=months)
    return forecast
```

**Implementation:** Add `statsmodels` and `scikit-learn` for ML

---

### Phase 2: Vector Embeddings & Semantic Search (1 week)

**Product Similarity:**
- Generate embeddings for products using Gemini
- Store in ChromaDB or Pinecone
- Enable: "Find products similar to [product]"
- Recommendations: "Customers who bought X also bought..."

```python
# Vector search
embeddings = generate_embeddings(product_descriptions)
vectorstore = Chroma(embeddings)
similar = vectorstore.similarity_search("electronics", k=5)
```

**Implementation:** Add ChromaDB, update prompts for RAG

---

### Phase 3: Multi-Agent Specialization (1-2 weeks)

**Specialized Agents:**
- ðŸŽ¯ **Sales Agent:** Revenue, trends, product performance
- ðŸª **Seller Agent:** Seller metrics, inventory, performance
- ðŸ‘¥ **Customer Agent:** Lifetime value, segmentation, churn
- ðŸ’° **Finance Agent:** Costs, margins, profitability
- ðŸ“¦ **Ops Agent:** Shipping times, logistics, fulfillment

```python
class SalesAgent:
    def handle_query(self, question):
        if "revenue" in question.lower():
            return self.revenue_query(question)
        elif "trend" in question.lower():
            return self.trend_query(question)

class CustomerAgent:
    def handle_query(self, question):
        if "lifetime value" in question.lower():
            return self.clv_query(question)
```

**Implementation:** Router agent to dispatch to specialists

---

### Phase 4: Real-time Dashboards (1 week)

**Auto-Generated KPIs:**
- Real-time sales dashboard
- Inventory status
- Seller performance leaderboard
- Customer acquisition funnel

```python
# Auto-generate dashboard
def auto_dashboard():
    metrics = {
        "today_revenue": get_today_revenue(),
        "avg_order_value": get_aov(),
        "top_category": get_top_category(),
        "seller_count": get_active_sellers()
    }
    render_dashboard(metrics)
```

**Implementation:** Plotly Dash or Streamlit multipage app

---

### Phase 5: Authentication & Multi-User (1 week)

**User Management:**
- Admin login with credentials
- Role-based access control (RBAC)
- User-specific dashboards
- Query permission levels

```python
# Authentication
@st.cache_resource
def init_auth():
    return Auth0Manager()

if not init_auth().is_authenticated():
    st.error("Please log in")
    st.stop()
```

**Implementation:** Streamlit Cloud secrets, Auth0, or simple DB

---

### Phase 6: Mobile App & Progressive Web App (2 weeks)

**Mobile Version:**
- React Native or Flutter app
- Offline query caching
- Voice input for queries
- Push notifications for insights

**PWA Features:**
- Install as app
- Offline mode
- Background sync

**Implementation:** Separate frontend repo, API backend

---

### Phase 7: Production Deployment (1 week)

**Infrastructure:**
- Move to PostgreSQL (not SQLite)
- Deploy API backend (FastAPI)
- Frontend on Vercel/Netlify
- Caching layer (Redis)
- Monitoring (Datadog/NewRelic)

**Architecture:**
```
Frontend (Next.js) â† API (FastAPI) â† Database (PostgreSQL)
                        â†“
                  Gemini API
                        â†“
                    Cache (Redis)
```

**Implementation:** Docker, Kubernetes, CI/CD pipeline

---

### Phase 8: Advanced Features

**Smart Query Suggestions:**
- Learn user preferences
- Suggest relevant questions
- Auto-complete based on history

**Report Generation:**
- PDF/Excel exports with formatting
- Scheduled reports
- Email delivery

**Collaborative Features:**
- Share queries with team
- Comment on results
- Pin important queries

**Data Lineage:**
- Show data sources and transformations
- Audit trail of all queries
- Data governance compliance

---

## ðŸ› Troubleshooting

### Issue: "No tables found in database"

**Causes:**
- CSV files not in `data/` folder
- CSV files not named correctly
- Database file corrupted

**Solutions:**
```bash
# Verify files exist
ls data/olist_*.csv

# Delete corrupted database
rm ecommerce.db

# Restart app
streamlit run app.py
```

---

### Issue: "SQLite threading error"

**Cause:** Old version of code without thread-safe connection

**Solution:** Update to latest code with `check_same_thread=False`

---

### Issue: "API Key not working"

**Causes:**
- Key not in `.env` file
- Key expired
- API quota exceeded

**Solutions:**
```bash
# Check .env
cat .env

# Get new key at https://aistudio.google.com/apikey
# Update .env and restart app
```

---

### Issue: "Generated SQL is invalid"

**Cause:** Gemini returned malformed SQL

**Solution:** 
- Try rephrasing question
- Use template query instead
- Check schema in sidebar

**If persistent:**
```bash
# Enable debug logging
export DEBUG=1
streamlit run app.py
```

---

### Issue: "Slow query execution"

**Cause:** Query scanning large tables without indexes

**Solution:**
```sql
-- Add indexes
CREATE INDEX idx_order_customer ON orders(customer_id);
CREATE INDEX idx_item_order ON order_items(order_id);
CREATE INDEX idx_item_product ON order_items(product_id);
```

---

## ðŸ“ Development

### Running Tests

```bash
# Run unit tests
pytest tests/

# Run with coverage
pytest --cov=. tests/
```

### Code Style

```bash
# Format code
black app.py

# Lint
pylint app.py

# Type checking
mypy app.py
```

---

## ðŸ“„ License

MIT License - see LICENSE file

---

## ðŸ¤ Contributing

Contributions welcome! Please:

1. Fork repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

---

## ðŸ“ž Support

**Questions or issues?**

- ðŸ“§ Email: [your-email]
- ðŸ› Issues: https://github.com/YOUR_USERNAME/maersk-ecommerce-ai/issues
- ðŸ’¬ Discussions: https://github.com/YOUR_USERNAME/maersk-ecommerce-ai/discussions

---

## ðŸŽ“ Learning Resources

**Built with these technologies:**

- [Streamlit Docs](https://docs.streamlit.io)
- [Google Gemini API](https://ai.google.dev/docs)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [SQLite Tutorial](https://www.sqlite.org/docs.html)

**Related Projects:**

- [LangChain](https://python.langchain.com/) - LLM orchestration
- [LlamaIndex](https://docs.llamaindex.ai/) - Data indexing
- [ChromaDB](https://docs.trychroma.com/) - Vector embeddings

---

## âœ¨ Acknowledgments

- ðŸ™ Brazilian E-Commerce Dataset by Olist (Kaggle)
- ðŸ™ Google for Gemini API
- ðŸ™ Streamlit team for excellent framework
- ðŸ™ Maersk for this opportunity

---

**Built with â¤ï¸ for the Maersk AI/ML Internship**

Last Updated: 2024
